---
title: 梯度下降法怎么求最佳步长
date: 2018-02-27 06:07:31
tags: 机器学习
mathjax: true
---

在梯度下降法(求最小值)里, `x`迭代的方向是梯度的反方向, 但是我们要选择一个步长使得函数值的确是下降的, 假设函数形式如下:

<!--more -->

`\[
f(\textbf{x})=  \textbf{x}^T\textbf{A}\textbf{x} + 2\textbf{b}^T + c
\]`

> 其中`\(\textbf{x}\)`为向量.


设`\(\textbf{d}\)`是负梯度方向, 那么, 我们的目标是解:

`\[
min_{\alpha>=0}f(\textbf{x}+\alpha \textbf{d})
\]`

中的`\(\alpha\)`.

### 解:

令 `\(h(\alpha)=f(x+\alpha d)\)`

函数最小值肯定是在导数为0时取得. 即:

`\[
{\partial h(\alpha) \over \partial \alpha} = \textbf{0}
\]`

1, 先求梯度:

`\[
\nabla f(x)=2A\textbf{x} + a \textbf{b}
\]`

2, 求偏导


根据链式法则有:

`\[
\begin{align}
{\partial h \over \partial \alpha} &= d^T[\nabla f(x + \alpha d)] \\
                                   &= d^T [2A(x+\alpha d) + 2b] \\
                                   &= d^T[2Ax+2b] + 2 \alpha d^T A d  \\
                                   &= d^T \nabla f(x) + 2 \alpha d^T A d
\end{align}
\]`

3, 由于导数为0, 所以有:

`\[
d^T \nabla f(x) + 2 \alpha d^T A d = 0 \\
\alpha = - {\ {d^T \nabla f(x)} \over {2 d^T A d}\ }
\]`

> 这是机器学习数学基础课程作业.